{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import jieba\n",
    "import gensim\n",
    "from smart_open import smart_open\n",
    "from sklearn.externals import joblib\n",
    "import xgboost as xgb\n",
    "\n",
    "ANS = ['a', 'b', 'c', 'd', 'e']\n",
    "FEATURES = ['no', 'w_idx', 'word', 'cos_ref','cos_syn1', 'cos_syn0', 'dist_syn0', 'target']\n",
    "WINDOW = 10\n",
    "VEC_SIZE = 100\n",
    "\n",
    "def simple_preprocess(content):\n",
    "    pat = '︽⊙＿⊙︽'\n",
    "    if content.find(pat) < 0: pat = '︽⊙＿⊙'\n",
    "    \n",
    "    content = content.strip().replace(pat, '龐燮傍謝')\n",
    "    wlist = list(jieba.cut(content))\n",
    "    qidx = []\n",
    "    i = 0\n",
    "    for w in wlist:\n",
    "        if w == '龐燮傍謝':\n",
    "            wlist[i] = '*'\n",
    "            qidx.append(i)\n",
    "        i += 1\n",
    "    return (wlist, qidx)\n",
    "\n",
    "def normalize_vec(vec):\n",
    "    mag = ((vec * vec).sum()) ** 0.5\n",
    "    return vec / mag\n",
    "\n",
    "def build_estimate_samples(wlist, qidx):\n",
    "    temp = wlist[:]\n",
    "    est_sen = []\n",
    "    sen_len = len(wlist)\n",
    "    for i in qidx:\n",
    "        head = max(i - WINDOW, 0)\n",
    "        tail = min(i + WINDOW, sen_len)\n",
    "        est_sen.append(wlist[head : i] + wlist[i + 1 : tail])\n",
    "    return est_sen\n",
    "\n",
    "def generate_feature(no, w_list, opt_list, syn0_model, syn1, prefix, ans = None):\n",
    "    # input sample: \n",
    "    # w_list = ['高雄','转','144','次','自强号','1700','高雄','开','1923','到','1940','到','台北']\n",
    "    # opt_list = ['两用', '阿明', '员林', '碎屑', '精力']\n",
    "    # ans = 'c'\n",
    "    # prefix = 'cbow'\n",
    "    opt_num = len(opt_list)\n",
    "    if ans: ans = opt_list[ANS.index(ans)]  # ans: 'c' --> '员林'\n",
    "    hidd_vec = np.zeros(VEC_SIZE)\n",
    "    for w in w_list:\n",
    "        if w in syn0_model and w != u'*': hidd_vec += syn0_model[w]\n",
    "    feats = []\n",
    "    for w in opt_list:\n",
    "        if w in syn0_model: \n",
    "            w_idx = syn0_model.vocab[w].index\n",
    "            cos_ref = np.dot(syn0_model[w], syn1[w_idx])\n",
    "#             cos_syn1 = np.dot(hidd_vec, syn1[w_idx])\n",
    "            cos_syn1 = np.dot(normalize_vec(hidd_vec), normalize_vec(syn1[w_idx]))\n",
    "#             cos_syn0 = np.dot(hidd_vec, syn0_model[w])\n",
    "            cos_syn0 = np.dot(normalize_vec(hidd_vec), normalize_vec(syn0_model[w]))\n",
    "            dist_syn0 = sum((hidd_vec - syn0_model[w]) ** 2)\n",
    "            feats.append([no, w_idx, w, cos_ref, cos_syn1, cos_syn0, dist_syn0])\n",
    "#             if w == ans:\n",
    "#                 feats.append([no, w_idx, w, cos_ref, cos_syn1, cos_syn0, dist_syn0, 1])\n",
    "#             else:\n",
    "#                 feats.append([no, w_idx, w, cos_ref, cos_syn1, cos_syn0, dist_syn0, 0])\n",
    "        else:\n",
    "            feats.append([no, 0, '</s>', 0, 0, 0, 0])\n",
    "            print(no,w, opt_list)\n",
    "            \n",
    "    df = pd.DataFrame(feats, columns=[prefix + '_' + f for f in FEATURES[:-1]])\n",
    "    cols_to_norm = [prefix + '_' + f for f in FEATURES[4:-1]]\n",
    "    df[cols_to_norm] = (df[cols_to_norm] - df[cols_to_norm].mean()) / df[cols_to_norm].std()\n",
    "#     df[cols_to_norm] = (df[cols_to_norm] - df[cols_to_norm].min()) / (df[cols_to_norm].max() - df[cols_to_norm].min())\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_model(path, prefix):\n",
    "    # input sample:\n",
    "    # path = 'w2v-experiment/model/'\n",
    "    # prefix = 'sk'\n",
    "    model = gensim.models.Word2Vec.load_word2vec_format(path + prefix + '-syn0.bin', binary = True)\n",
    "    vocab_size, vector_size = model.syn0.shape\n",
    "    syn1neg = np.zeros((vocab_size, vector_size), dtype=np.float32)\n",
    "    binary_len = np.dtype(np.float32).itemsize * vector_size\n",
    "    with smart_open(path + prefix + '-syn1neg.bin') as fin:\n",
    "        for i in range(vocab_size):\n",
    "            weights = np.fromstring(fin.read(binary_len), dtype=np.float32)\n",
    "            syn1neg[i] = weights\n",
    "    return (model, syn1neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jieba.add_word('龐燮傍謝', freq=10, tag='xx')\n",
    "# jieba.load_userdict('data/zhwiki-cn-clean')\n",
    "# jieba.load_userdict('data/dict-txt-big')\n",
    "# path = 'w2v-experiment/model/'\n",
    "# cbow_model, cbow_syn1neg = load_model(path, 'cbow')\n",
    "# sk_model, sk_syn1neg = load_model(path, 'sk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrmodel = joblib.load('w2v-experiment/model/lrmodel_cbow+sk.pkl')\n",
    "bst = xgb.Booster({'nthread':4})\n",
    "bst.load_model('w2v-experiment/model/xgb.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 蚊液 ['纪念堂', '脾气', '茶道', 'line', '蚊液']\n",
      "1 蚊液 ['纪念堂', '脾气', '茶道', 'line', '蚊液']\n",
      "75.0\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "pre_path = 'question_samples/battle/preliminary/'\n",
    "pre_file = 'round' + str(i) + '-cn.txt'\n",
    "# pre_path = 'question_samples/battle/final/'\n",
    "# pre_file = 'all-cn.txt'\n",
    "ANSWER_LIST = []\n",
    "\n",
    "with open(pre_path + pre_file, 'r') as f:\n",
    "    for line in f:\n",
    "        j += 1\n",
    "        try:\n",
    "            no, content, a, b, c, d, e = re.findall(r'\\[(\\d+)\\](.*)### a:(.*), b:(.*), c:(.*), d:(.*), e:(.*)\\[end\\]', line.lower())[0]\n",
    "        except:\n",
    "            break\n",
    "        wlist, qidx = simple_preprocess(content.strip())\n",
    "        opt_list = [a.strip(), b.strip(), c.strip(), d.strip(), e.strip()]\n",
    "        sen_list = build_estimate_samples(wlist, qidx)\n",
    "        n_sen = len(sen_list)\n",
    "        PREDICT = np.zeros((n_sen, 5))\n",
    "        for i in range(n_sen):\n",
    "            cbow_df = generate_feature(no, sen_list[i], opt_list, cbow_model, cbow_syn1neg, 'cbow')\n",
    "            cbow_df.drop(['cbow_no', 'cbow_word'], axis=1, inplace=True)\n",
    "            cbow_df.rename(columns = {'cbow_w_idx':'w_idx'}, inplace = True)\n",
    "            sk_df = generate_feature(no, sen_list[i], opt_list, sk_model, sk_syn1neg, 'sk')\n",
    "            sk_df.drop(['sk_w_idx'], axis=1, inplace=True)\n",
    "            df = pd.concat([cbow_df, sk_df], axis = 1)\n",
    "            df.drop(['sk_no', 'sk_word'], axis=1, inplace=True)\n",
    "            df[['w_idx']] = (df[['w_idx']] - df[['w_idx']].mean()) / df[['w_idx']].std()\n",
    "#             dtrain = xgb.DMatrix(data)\n",
    "#             PREDICT[i, :] = bst.predict(dtrain)\n",
    "#             PREDICT[i, :] = df['cbow_cos_syn1'].values\n",
    "            PREDICT[i, :] = lrmodel.predict_proba(df.values)[:,1]\n",
    "        ANSWER_LIST.append(ANS[PREDICT.mean(axis=0).argmax()])\n",
    "        \n",
    "n = len(ANSWER_LIST)\n",
    "REF_LIST = line.split()\n",
    "score = 0\n",
    "for i in range(n):\n",
    "    if REF_LIST[i] == ANSWER_LIST[i]: score += (100/float(n))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.30329689e-05,   9.69766385e-01,   5.15767759e-03,\n",
       "          2.63725882e-02,   2.26159962e-02]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in final round\n",
    "# OK-Computer got 4 wrong answers out of 22 questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
