{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/tripper/Desktop/project/pixnet-nlp/data/DICT_CK+jieba_lower ...\n",
      "Loading model from cache /var/folders/4_/b_9vfbwx41g4t48jrzr0r4vm0000gn/T/jieba.uaab2b61a375629a86d8bcbcdd9e861b1.cache\n",
      "Loading model cost 1.268 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from smart_open import smart_open\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "ANS = ['a', 'b', 'c', 'd', 'e']\n",
    "WINDOW = 10\n",
    "VEC_SIZE = 100\n",
    "\n",
    "jieba.set_dictionary('../data/DICT_CK+jieba_lower')\n",
    "jieba.add_word('龐燮傍謝', freq=10, tag='xx')\n",
    "\n",
    "def normalize_vec(vec):\n",
    "    mag = ((vec * vec).sum()) ** 0.5\n",
    "    return vec / mag\n",
    "\n",
    "def estimate_ans(est_sen_list, options, model, syn1neg):\n",
    "    n_sen = float(len(est_sen_list))\n",
    "    option_vec_idx = []\n",
    "    for w in options:\n",
    "        if w in model: option_vec_idx.append(model.vocab[w].index)\n",
    "        else: \n",
    "            option_vec_idx.append(-1)\n",
    "#             return -1\n",
    "    score = [0., 0., 0., 0., 0.]\n",
    "    for wlist in est_sen_list:\n",
    "        arr = np.zeros(VEC_SIZE)\n",
    "        for w in wlist:\n",
    "            if w in model and w != u'*': arr += model[w]\n",
    "        for i in range(5):\n",
    "            if option_vec_idx[i] >= 0: \n",
    "#                 score[i] += np.dot(normalize_vec(arr), normalize_vec(model[model.index2word[option_vec_idx[i]]]))\n",
    "                score[i] += np.dot(normalize_vec(arr), normalize_vec(syn1neg[option_vec_idx[i]]))\n",
    "#                 score[i] += np.dot(arr, syn1neg[option_vec_idx[i]])\n",
    "    for i in range(5):\n",
    "        score[i] /= n_sen\n",
    "    \n",
    "    return ANS[score.index(max(score))]\n",
    "\n",
    "\n",
    "def build_estimate_samples(wlist, qidx):\n",
    "    temp = wlist[:]\n",
    "    est_sen = []\n",
    "    sen_len = len(wlist)\n",
    "    for i in qidx:\n",
    "        head = max(i - WINDOW, 0)\n",
    "        tail = min(i + WINDOW, sen_len)\n",
    "        est_sen.append(wlist[head : i] + wlist[i + 1 : tail])\n",
    "    return est_sen\n",
    "\n",
    "\n",
    "def jieba_preprocess(content):\n",
    "    content = content.strip().lower().replace('︽⊙＿⊙︽', '龐燮傍謝')\n",
    "    wlist = list(jieba.cut(content))\n",
    "    qidx = []\n",
    "    for i, w in enumerate(wlist):\n",
    "        if w == '龐燮傍謝':\n",
    "            wlist[i] = '*'\n",
    "            qidx.append(i)\n",
    "    return (wlist, qidx)\n",
    "\n",
    "def format_pre_sample(row):\n",
    "    no = row.no\n",
    "    wlist, qidx = jieba_preprocess(row.content)\n",
    "    options = [x.strip().lower() for x in list(row[['a','b','c','d','e']].values)]\n",
    "    ans = row.ans\n",
    "    return no, wlist, qidx, options, ans\n",
    "\n",
    "def load_model(path, prefix):\n",
    "    # input sample:\n",
    "    # path = 'w2v-experiment/model/'\n",
    "    # prefix = 'sk'\n",
    "    model = gensim.models.Word2Vec.load_word2vec_format(path + prefix + '-syn0.bin', binary = True)\n",
    "    vocab_size, vector_size = model.syn0.shape\n",
    "    syn1neg = np.zeros((vocab_size, vector_size), dtype=np.float32)\n",
    "    binary_len = np.dtype(np.float32).itemsize * vector_size\n",
    "    with smart_open(path + prefix + '-syn1neg.bin') as fin:\n",
    "        for i in range(vocab_size):\n",
    "            weights = np.fromstring(fin.read(binary_len), dtype=np.float32)\n",
    "            syn1neg[i] = weights\n",
    "    syn1neg[0, :] = syn1neg[1 : vocab_size/2, :].mean(axis=0)\n",
    "    model.syn0[0, :] = model.syn0[1 : vocab_size/2, :].mean(axis=0)\n",
    "    return (model, syn1neg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'model/'\n",
    "cbow_model, cbow_syn1neg = load_model(path, 'cbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_samples = pd.read_csv('../question_sample/pre/raw_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7747252747252747\n",
      "0.22527472527472528\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "wrong = 0\n",
    "total = 0\n",
    "wtf = 0\n",
    "for index, row in pre_samples.iterrows():\n",
    "    no, wlist, qidx, options, ans = format_pre_sample(row)\n",
    "    est_sen_list = build_estimate_samples(wlist, qidx)\n",
    "    if len(est_sen_list) > 0:\n",
    "        predict = estimate_ans(est_sen_list, options, cbow_model, cbow_syn1neg)\n",
    "        if(predict == ans): right += 1\n",
    "        else: wrong += 1\n",
    "        total += 1\n",
    "    else: wtf += 1\n",
    "    \n",
    "print(right/total)\n",
    "print(wrong/total)\n",
    "print(wtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>content</th>\n",
       "      <th>ans</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>ans_ref</th>\n",
       "      <th>url</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>臉上比較油的時候我都會習慣讓︽⊙＿⊙︽多停留個10秒左右，會比馬上就洗掉清潔得更乾淨一點唷</td>\n",
       "      <td>c</td>\n",
       "      <td>金花</td>\n",
       "      <td>蝶舞</td>\n",
       "      <td>洗面乳</td>\n",
       "      <td>蛋糕</td>\n",
       "      <td>石屋</td>\n",
       "      <td>洗面乳</td>\n",
       "      <td>http://uniquevera.pixnet.net/blog/post/32578815</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>遊客服務中心除了可以拿地圖、納涼、放水和裝水之外，也有山藥、地瓜、地瓜蛋捲等︽⊙＿⊙︽特產伴...</td>\n",
       "      <td>a</td>\n",
       "      <td>三芝</td>\n",
       "      <td>馬力</td>\n",
       "      <td>土星</td>\n",
       "      <td>帽帽</td>\n",
       "      <td>黃博</td>\n",
       "      <td>三芝</td>\n",
       "      <td>http://bajenny.pixnet.net/blog/post/31640255</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>這瓶︽⊙＿⊙︽我大概聖誕節開始用, 目前用2個禮拜, 剛好都是我皮膚最疲勞狀況最不好的</td>\n",
       "      <td>b</td>\n",
       "      <td>視角</td>\n",
       "      <td>精華液</td>\n",
       "      <td>八甲</td>\n",
       "      <td>調性</td>\n",
       "      <td>香火</td>\n",
       "      <td>精華液</td>\n",
       "      <td>http://ksnancy.pixnet.net/blog/post/405460378</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>在白米木屐館的隔壁，大家有去︽⊙＿⊙︽的話，一定要順道去貪小便宜吃好料，才會不枉此行啊～</td>\n",
       "      <td>c</td>\n",
       "      <td>工作者</td>\n",
       "      <td>代理</td>\n",
       "      <td>蘇澳</td>\n",
       "      <td>炒年糕</td>\n",
       "      <td>冰柱</td>\n",
       "      <td>蘇澳</td>\n",
       "      <td>http://k640640.pixnet.net/blog/post/27233228</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>※墾丁大街/後壁湖/紅柴坑/墾丁民宿/墾丁飯店/︽⊙＿⊙︽小吃/墾丁景點美食相關遊記</td>\n",
       "      <td>d</td>\n",
       "      <td>小家庭</td>\n",
       "      <td>繪圖</td>\n",
       "      <td>薄紗</td>\n",
       "      <td>恆春</td>\n",
       "      <td>限定版</td>\n",
       "      <td>恆春</td>\n",
       "      <td>http://bajenny.pixnet.net/blog/post/41742487</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                            content ans    a    b    c  \\\n",
       "0   0      臉上比較油的時候我都會習慣讓︽⊙＿⊙︽多停留個10秒左右，會比馬上就洗掉清潔得更乾淨一點唷   c   金花   蝶舞  洗面乳   \n",
       "1   1  遊客服務中心除了可以拿地圖、納涼、放水和裝水之外，也有山藥、地瓜、地瓜蛋捲等︽⊙＿⊙︽特產伴...   a   三芝   馬力   土星   \n",
       "2   2        這瓶︽⊙＿⊙︽我大概聖誕節開始用, 目前用2個禮拜, 剛好都是我皮膚最疲勞狀況最不好的   b   視角  精華液   八甲   \n",
       "3   3       在白米木屐館的隔壁，大家有去︽⊙＿⊙︽的話，一定要順道去貪小便宜吃好料，才會不枉此行啊～   c  工作者   代理   蘇澳   \n",
       "4   4         ※墾丁大街/後壁湖/紅柴坑/墾丁民宿/墾丁飯店/︽⊙＿⊙︽小吃/墾丁景點美食相關遊記   d  小家庭   繪圖   薄紗   \n",
       "\n",
       "     d    e ans_ref                                              url degree  \n",
       "0   蛋糕   石屋     洗面乳  http://uniquevera.pixnet.net/blog/post/32578815   easy  \n",
       "1   帽帽   黃博      三芝     http://bajenny.pixnet.net/blog/post/31640255   easy  \n",
       "2   調性   香火     精華液    http://ksnancy.pixnet.net/blog/post/405460378   easy  \n",
       "3  炒年糕   冰柱      蘇澳     http://k640640.pixnet.net/blog/post/27233228   easy  \n",
       "4   恆春  限定版      恆春     http://bajenny.pixnet.net/blog/post/41742487   easy  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_samples = pd.read_csv('../question_sample/official/hackathon_1000.tsv', sep='\\t', names=['no','content', 'ans', 'a', 'b', 'c', 'd', 'e', 'ans_ref', 'url', 'degree'])\n",
    "post_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7841269841269841\n",
      "0.21587301587301588\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "wrong = 0\n",
    "total = 0\n",
    "wtf = 0\n",
    "for index, row in post_samples.iterrows():\n",
    "    no, wlist, qidx, options, ans = format_pre_sample(row)\n",
    "    est_sen_list = build_estimate_samples(wlist, qidx)\n",
    "    if len(est_sen_list) > 0:\n",
    "        predict = estimate_ans(est_sen_list, options, cbow_model, cbow_syn1neg)\n",
    "        if(predict == ans): right += 1\n",
    "        else: wrong += 1\n",
    "        total += 1\n",
    "    else: wtf += 1\n",
    "    \n",
    "print(right/total)\n",
    "print(wrong/total)\n",
    "print(wtf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
