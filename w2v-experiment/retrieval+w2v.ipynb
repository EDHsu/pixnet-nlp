{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "# import jieba\n",
    "import gensim\n",
    "from smart_open import smart_open\n",
    "import codecs\n",
    "import random\n",
    "ANS = ['a', 'b', 'c', 'd', 'e']\n",
    "# FEATURES = ['no', 'w_idx', 'word', 'cos_ref','cos_syn1', 'cos_syn0', 'dist_syn0', 'target']\n",
    "WINDOW = 10\n",
    "VEC_SIZE = 100\n",
    "\n",
    "class KeyRetrieval(object):\n",
    "    \n",
    "    def __init__(self, raw_content, query_num = 5, query_len = 20):\n",
    "        self.query_num = query_num\n",
    "        self.query_len = query_len\n",
    "        self.raw_content = raw_content\n",
    "        self.rand_query = []\n",
    "        self.add_rand_query()\n",
    "    def add_rand_query(self, content = None):\n",
    "        if content == None: content = self.raw_content\n",
    "        match = list(re.finditer('︽⊙＿⊙︽', content))\n",
    "        match_num = len(match)\n",
    "        content_len = len(content)\n",
    "        for i in range(self.query_num):\n",
    "            k = random.choice(range(match_num))\n",
    "            m = match[k]\n",
    "            if m.span()[0] > 0:\n",
    "                ihead = random.choice(range(max(0, m.span()[0] - self.query_len), m.span()[0]))\n",
    "            else: ihead = 0\n",
    "            if m.span()[1] < content_len:\n",
    "                iend = random.choice(range(m.span()[1], min(len(content), m.span()[1] + self.query_len)))\n",
    "            else: iend = content_len - 1\n",
    "            \n",
    "            if k > 0: \n",
    "                pre_m = match[k - 1]\n",
    "                if ihead < pre_m.span()[1]: ihead = pre_m.span()[1]\n",
    "            \n",
    "            if k < match_num - 1: \n",
    "                aft_m = match[k + 1]\n",
    "                if iend >= aft_m.span()[0]: iend = aft_m.span()[0] - 1\n",
    "            \n",
    "            q = content[ihead : iend + 1]\n",
    "            if m.span()[0] == 0: \n",
    "                q = '\\n' + q\n",
    "            if m.span()[1] == content_len: q = q + '\\n'\n",
    "            self.rand_query.append(self.format_query(q))\n",
    "    def set_rand_query(self):\n",
    "        self.rand_query = []\n",
    "        self.add_rand_query()\n",
    "\n",
    "    def retrieve(self):\n",
    "        key = []\n",
    "        for q in self.rand_query:\n",
    "#             print(q)\n",
    "            try:\n",
    "                m = re.findall(q, SEN_POOL)[0]\n",
    "                if m: key.append(m)\n",
    "            except:\n",
    "                print('retrieval exception: ' + q)\n",
    "                continue\n",
    "        if len(key) > 0:\n",
    "            count = {}\n",
    "            for w in key:\n",
    "                if w in count:\n",
    "                    count[w] += 1\n",
    "                else: count[w] = 0\n",
    "            return sorted(count.items(), reverse=True, key=lambda tup: tup[1])[0][0]\n",
    "            \n",
    "                  \n",
    "    def format_query(self, raw_query = None):\n",
    "        if raw_query == None: raw_query = self.raw_content\n",
    "        return re.sub(r'([\\.\\^\\$\\|\\*\\+\\?\\\\\\{\\}\\[\\]\\(\\)])', r'\\\\\\1', raw_query).replace('︽⊙＿⊙︽', '(.{2,9})')\n",
    "    \n",
    "        \n",
    "\n",
    "def load_model(path, prefix):\n",
    "    # input sample:\n",
    "    # path = 'w2v-experiment/model/'\n",
    "    # prefix = 'sk'\n",
    "    model = gensim.models.Word2Vec.load_word2vec_format(path + prefix + '-syn0.bin', binary = True)\n",
    "    vocab_size, vector_size = model.syn0.shape\n",
    "    syn1neg = np.zeros((vocab_size, vector_size), dtype=np.float32)\n",
    "    binary_len = np.dtype(np.float32).itemsize * vector_size\n",
    "    with smart_open(path + prefix + '-syn1neg.bin') as fin:\n",
    "        for i in range(vocab_size):\n",
    "            weights = np.fromstring(fin.read(binary_len), dtype=np.float32)\n",
    "            syn1neg[i] = weights\n",
    "    syn1neg[0, :] = syn1neg[1 : vocab_size/2, :].mean(axis=0)\n",
    "    model.syn0[0, :] = model.syn0[1 : vocab_size/2, :].mean(axis=0)\n",
    "    return (model, syn1neg)\n",
    "\n",
    "\n",
    "def simple_preprocess_A(line):\n",
    "    try:\n",
    "        no, content, a, b, c, d, e = re.findall(r'\\[(\\d+)\\](.*)### a:(.*), b:(.*), c:(.*), d:(.*), e:(.*)\\[end\\]', line.lower())[0]\n",
    "    except:\n",
    "        return {'ans': line.split()}\n",
    "    return {'no': no, 'content': content, 'opt_list': [a.strip(), b.strip(), c.strip(), d.strip(), e.strip()]}\n",
    "\n",
    "def normalize_vec(vec):\n",
    "    mag = ((vec * vec).sum()) ** 0.5\n",
    "    return vec / mag\n",
    "\n",
    "\n",
    "def w2v_cosine(key, opt_list, syn0_model, syn1neg):\n",
    "    arr = np.zeros(len(opt_list))\n",
    "    if key in syn0_model:\n",
    "        hidd_vec = normalize_vec(syn0_model[key])\n",
    "        for i in range(len(opt_list)):\n",
    "            if opt_list[i] in syn0_model:\n",
    "                w_idx = syn0_model.vocab[opt_list[i]].index\n",
    "#                 arr[i] = np.dot(hidd_vec, (syn0_model[opt_list[i]])) \\\n",
    "#                        + np.dot(hidd_vec, (syn1neg[w_idx]))\n",
    "#                 arr[i] = np.dot(hidd_vec, (syn1neg[w_idx]))\n",
    "                arr[i] = np.dot(hidd_vec, normalize_vec(syn0_model[opt_list[i]])) \\\n",
    "                       + np.dot(hidd_vec, normalize_vec(syn1neg[w_idx]))\n",
    "            else:\n",
    "#                 arr[i] = np.dot(hidd_vec, (syn1neg[0]))\n",
    "                arr[i] = np.dot(hidd_vec, normalize_vec(syn0_model.syn0[0])) \\\n",
    "                       + np.dot(hidd_vec, normalize_vec(syn1neg[0]))\n",
    "                print(arr[i])\n",
    "        return ANS[arr.argmax()]\n",
    "                \n",
    "    else:\n",
    "        return '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'model/'\n",
    "# cbow_model, cbow_syn1neg = load_model(path, 'cbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168\n"
     ]
    }
   ],
   "source": [
    "# SEN_POOL = ''\n",
    "# with codecs.open('../data/content-cn-lower.txt', 'r', encoding='utf-8') as f:\n",
    "#     outer_buf = []\n",
    "#     inner_buf = [''] * 10000\n",
    "#     buf_idx = 0\n",
    "#     for line in f:\n",
    "#         inner_buf[buf_idx] = line\n",
    "#         buf_idx += 1\n",
    "#         if buf_idx >= 10000: \n",
    "#             buf_idx = 0\n",
    "#             outer_buf.append(''.join(inner_buf))\n",
    "#     outer_buf.append(''.join(inner_buf[:buf_idx]))\n",
    "\n",
    "# print(len(outer_buf))\n",
    "# SEN_POOL = ''.join(outer_buf)\n",
    "# print(repr(SEN_POOL[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n(.{1,10})这双2014秋冬的si', '\\n(.{1,10})这双2014秋冬的sim']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample = '发亮的程度直接可以媲美我以/前大费周章的用隔离霜+︽⊙＿⊙︽+蜜粉+打亮修容'\n",
    "# sample = re.sub(r'([\\.\\^\\$\\*\\+\\?\\\\\\{\\}\\[\\]\\(\\)])', r'\\\\\\1',sample)\n",
    "sample = '︽⊙＿⊙︽这双2014秋冬的simone过膝靴是笔挺率性的风格。如果想要笔直长靴的造型，simone是满分。皮又厚又挺，穿过也不皱不变形。而且雾面和剪裁都很修饰腿型，也格外适合搭裤装'\n",
    "q = KeyRetrieval(sample)\n",
    "q.rand_query\n",
    "# m = re.findall(sample, SEN_POOL)[0]\n",
    "# print(str(m))\n",
    "# k = SEN_POOL.find(sample)\n",
    "# SEN_POOL[k - 20 : k + len(sample) + 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 洗面乳\n",
      "2 三芝\n",
      "retrieval exception:  这瓶(.{2,15})我大概圣诞节开始用\n",
      "retrieval exception:  这瓶(.{2,15})我大\n",
      "retrieval exception:  这瓶(.{2,15})我大概圣诞节开始用, 目前用2\n",
      "3 精华液\n",
      "4 苏澳\n",
      "retrieval exception: /垦丁饭店/(.{2,15})小吃/垦丁景点美食相关游记  \n",
      "retrieval exception: 壁湖/红柴坑/垦丁民宿/垦丁饭店/(.{2,15})小吃/垦丁景点美食相关游记   \n",
      "5 恒春\n",
      "retrieval exception: 前身是花莲酒厂　是这两年才开放的(.{2,15})新景点　所以网路上能找到的资料不多  \n",
      "retrieval exception: 区前身是花莲酒厂　是这两年才开放的(.{2,15})新景点　所以网路上能找到的资料不多 \n",
      "6 花莲市\n",
      "7 山上\n",
      "8 保湿精华\n",
      "retrieval exception: 无法使用(.{2,15})系列的孩子  \n",
      "retrieval exception: 法使用(.{2,15})系列的孩子  \n",
      "9 粉底液\n",
      "retrieval exception: 便找10个人来问『高价和便宜的(.{2,15})有没有差别』 \n",
      "retrieval exception: 『高价和便宜的(.{2,15})有没有差别』  \n",
      "10 蜜粉\n",
      "retrieval exception: 多的(.{2,15})力就必须搭配其他产品     \n",
      "11 遮瑕\n",
      "12 玉里\n",
      "retrieval exception: 点下次来(.{2,15})说什么我都会来名汤阿   \n",
      "retrieval exception: 冲着这点下次来(.{2,15})说什么我都会来名汤阿  \n",
      "13 乌来\n",
      "14 书店\n",
      "15 稻田中\n",
      "16 gucci\n",
      "retrieval exception:  ４个月大的林小亮第一回长征到(.{2,15})，也是第一次\n",
      "17 台南\n",
      "retrieval exception: 的乡间村落下车：新港(.{2,15}) \n",
      "retrieval exception: 村落下车：新港(.{2,15})   \n",
      "retrieval exception: 有特色的乡间村落下车：新港(.{2,15})  \n",
      "retrieval exception: 个很有特色的乡间村落下车：新港(.{2,15}) \n",
      "18 路口  刚好在地下道上方\n",
      "19 ladurÉe\n",
      "20 孔庙\n",
      "0.119266480207\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "pre_path = '../question_samples/battle/preliminary/'\n",
    "pre_file = 'round' + str(i) + '-cn.txt'\n",
    "# pre_path = '../question_samples/battle/final/'\n",
    "# pre_file = 'all-cn.txt'\n",
    "PRED_LIST = []\n",
    "with codecs.open(pre_path + pre_file, 'r', encoding='utf-8') as f:\n",
    "    j = 1\n",
    "    for line in f:\n",
    "        d = simple_preprocess_A(line.lower())\n",
    "        if 'content' in d:\n",
    "#             print(d['no'], d['content'])\n",
    "            q = KeyRetrieval(d['content'])\n",
    "            key = q.retrieve()\n",
    "            print(d['no'], key)\n",
    "            if key:\n",
    "                found = False\n",
    "                for i in range(len(d['opt_list'])):\n",
    "                    if d['opt_list'][i] in key or key in d['opt_list'][i]:\n",
    "                        PRED_LIST.append((len(content), ANS[i]))\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found: PRED_LIST.append((len(content), w2v_cosine(key, d['opt_list'], cbow_model, cbow_syn1neg)))\n",
    "            else:\n",
    "                print('dunt no')\n",
    "                PRED_LIST.append((len(content), random.choice(ANS)))\n",
    "        j += 1\n",
    "#         if j > 13: break\n",
    "# key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c', 'a', 'b', 'c', 'd', 'b', 'b', 'b', 'e', 'e', 'd', 'c', 'b', 'b', 'c', 'd', 'd', '0', '0', 'd']\n",
      "['c', 'a', 'b', 'c', 'd', 'b', 'b', 'b', 'e', 'e', 'd', 'c', 'b', 'b', 'c', 'd', 'd', 'b', 'c', 'd']\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "pred = [x[1] for x in PRED_LIST]\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] == d['ans'][i]:  score += (100. / len(pred))\n",
    "print(pred)\n",
    "print(d['ans'])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>no</th>\n",
       "      <th>content</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2016-08-10-01-52-38.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>很想约人，但太远，骑机车载人又太冷，找人开车对司机又不好意思，光车程来回6小时，就自己速去速...</td>\n",
       "      <td>西门町</td>\n",
       "      <td>智恩寺</td>\n",
       "      <td>脆口</td>\n",
       "      <td>妈妈</td>\n",
       "      <td>湿地</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2016-08-10-01-52-38.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>︽⊙＿⊙︽的燕子口有个印地安人头像，这儿则据说有︽⊙＿⊙︽酋长头像，但我们并未找到正确位置</td>\n",
       "      <td>野口</td>\n",
       "      <td>缺点</td>\n",
       "      <td>台塑</td>\n",
       "      <td>太鲁阁</td>\n",
       "      <td>金属</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2016-08-10-01-52-38.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>或是擦除不小心沾到︽⊙＿⊙︽的皮肤也可以直接使用mdmmd.极致水漾除彩液，还蛮好清除的</td>\n",
       "      <td>prada</td>\n",
       "      <td>靴子</td>\n",
       "      <td>指甲油</td>\n",
       "      <td>cleansing</td>\n",
       "      <td>蛋型</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>2016-08-10-01-52-38.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>************************ 本文为︽⊙＿⊙︽邀稿 **********...</td>\n",
       "      <td>小木马</td>\n",
       "      <td>理想大地</td>\n",
       "      <td>叶记</td>\n",
       "      <td>新湖</td>\n",
       "      <td>阿灶伯</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>2016-08-10-01-52-38.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>我们住在埔里︽⊙＿⊙︽的稻湘村民宿，司机驾驶功力一流，狭窄的山路依然开得很妥当，一到民宿我们...</td>\n",
       "      <td>储水</td>\n",
       "      <td>外婆</td>\n",
       "      <td>桥头</td>\n",
       "      <td>锦记</td>\n",
       "      <td>山上</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file  no  \\\n",
       "545  2016-08-10-01-52-38.txt   1   \n",
       "546  2016-08-10-01-52-38.txt   2   \n",
       "547  2016-08-10-01-52-38.txt   3   \n",
       "548  2016-08-10-01-52-38.txt   4   \n",
       "549  2016-08-10-01-52-38.txt   5   \n",
       "\n",
       "                                               content      a     b    c  \\\n",
       "545  很想约人，但太远，骑机车载人又太冷，找人开车对司机又不好意思，光车程来回6小时，就自己速去速...    西门町   智恩寺   脆口   \n",
       "546      ︽⊙＿⊙︽的燕子口有个印地安人头像，这儿则据说有︽⊙＿⊙︽酋长头像，但我们并未找到正确位置     野口    缺点   台塑   \n",
       "547       或是擦除不小心沾到︽⊙＿⊙︽的皮肤也可以直接使用mdmmd.极致水漾除彩液，还蛮好清除的  prada    靴子  指甲油   \n",
       "548  ************************ 本文为︽⊙＿⊙︽邀稿 **********...    小木马  理想大地   叶记   \n",
       "549  我们住在埔里︽⊙＿⊙︽的稻湘村民宿，司机驾驶功力一流，狭窄的山路依然开得很妥当，一到民宿我们...     储水    外婆   桥头   \n",
       "\n",
       "             d    e ans  \n",
       "545         妈妈   湿地   a  \n",
       "546        太鲁阁   金属   d  \n",
       "547  cleansing   蛋型   c  \n",
       "548         新湖  阿灶伯   b  \n",
       "549         锦记   山上   e  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv('../question_samples/raw_samples_cn.csv')\n",
    "print(sample_df.shape)\n",
    "sample_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5726, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_idx</th>\n",
       "      <th>cbow_cos_ref</th>\n",
       "      <th>cbow_cos_syn1</th>\n",
       "      <th>cbow_cos_syn0</th>\n",
       "      <th>cbow_dist_syn0</th>\n",
       "      <th>sk_no</th>\n",
       "      <th>sk_word</th>\n",
       "      <th>sk_cos_ref</th>\n",
       "      <th>sk_cos_syn1</th>\n",
       "      <th>sk_cos_syn0</th>\n",
       "      <th>sk_dist_syn0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>10438</td>\n",
       "      <td>3.212975</td>\n",
       "      <td>-0.044324</td>\n",
       "      <td>0.853694</td>\n",
       "      <td>-0.839728</td>\n",
       "      <td>999</td>\n",
       "      <td>两用</td>\n",
       "      <td>4.656869</td>\n",
       "      <td>-0.257106</td>\n",
       "      <td>-0.291752</td>\n",
       "      <td>0.330412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>15661</td>\n",
       "      <td>4.379284</td>\n",
       "      <td>0.123536</td>\n",
       "      <td>-0.253477</td>\n",
       "      <td>0.213438</td>\n",
       "      <td>999</td>\n",
       "      <td>阿明</td>\n",
       "      <td>4.713268</td>\n",
       "      <td>0.607256</td>\n",
       "      <td>0.958114</td>\n",
       "      <td>-0.750441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>3171</td>\n",
       "      <td>2.885983</td>\n",
       "      <td>1.392450</td>\n",
       "      <td>1.179961</td>\n",
       "      <td>-1.197060</td>\n",
       "      <td>999</td>\n",
       "      <td>员林</td>\n",
       "      <td>6.344345</td>\n",
       "      <td>1.368895</td>\n",
       "      <td>0.831401</td>\n",
       "      <td>-1.211119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>30408</td>\n",
       "      <td>3.043319</td>\n",
       "      <td>-1.428999</td>\n",
       "      <td>-1.229303</td>\n",
       "      <td>1.189205</td>\n",
       "      <td>999</td>\n",
       "      <td>碎屑</td>\n",
       "      <td>2.994729</td>\n",
       "      <td>-1.186405</td>\n",
       "      <td>-1.518305</td>\n",
       "      <td>1.330615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>17496</td>\n",
       "      <td>2.659255</td>\n",
       "      <td>-0.042663</td>\n",
       "      <td>-0.550874</td>\n",
       "      <td>0.634144</td>\n",
       "      <td>999</td>\n",
       "      <td>精力</td>\n",
       "      <td>2.873720</td>\n",
       "      <td>-0.532640</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.300534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      w_idx  cbow_cos_ref  cbow_cos_syn1  cbow_cos_syn0  cbow_dist_syn0  \\\n",
       "5721  10438      3.212975      -0.044324       0.853694       -0.839728   \n",
       "5722  15661      4.379284       0.123536      -0.253477        0.213438   \n",
       "5723   3171      2.885983       1.392450       1.179961       -1.197060   \n",
       "5724  30408      3.043319      -1.428999      -1.229303        1.189205   \n",
       "5725  17496      2.659255      -0.042663      -0.550874        0.634144   \n",
       "\n",
       "      sk_no sk_word  sk_cos_ref  sk_cos_syn1  sk_cos_syn0  sk_dist_syn0  \\\n",
       "5721    999      两用    4.656869    -0.257106    -0.291752      0.330412   \n",
       "5722    999      阿明    4.713268     0.607256     0.958114     -0.750441   \n",
       "5723    999      员林    6.344345     1.368895     0.831401     -1.211119   \n",
       "5724    999      碎屑    2.994729    -1.186405    -1.518305      1.330615   \n",
       "5725    999      精力    2.873720    -0.532640     0.020542      0.300534   \n",
       "\n",
       "      target  \n",
       "5721       0  \n",
       "5722       0  \n",
       "5723       1  \n",
       "5724       0  \n",
       "5725       0  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_df = pd.read_csv('../question_official/overall_df.csv')\n",
    "print(official_df.shape)\n",
    "official_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 14, 15, 16, 17]\n",
      "35\n",
      "美我以︽⊙＿⊙︽前大费周章的用隔离霜+︽⊙＿⊙︽\n"
     ]
    }
   ],
   "source": [
    "sample = '发亮的程度直接可以媲美我以︽⊙＿⊙︽前大费周章的用隔离霜+︽⊙＿⊙︽.'\n",
    "m = list(re.finditer('︽⊙＿⊙︽', sample))\n",
    "print(list(range(m[0].span()[0], m[0].span()[1])))\n",
    "print(len(sample))\n",
    "print(sample[10:34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(29, 34), match='︽⊙＿⊙︽'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = {'a':6, 'b':4,\"c\": 9}\n",
    "sorted(count.items(), reverse=True, key=lambda tup: tup[1])[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
